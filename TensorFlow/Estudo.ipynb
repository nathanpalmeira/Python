{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudo de TensorFlow\n",
    "\n",
    "Varios exemplos de probramas para estudo da ferramenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://juliocprocha.wordpress.com/2017/08/28/uma-introducao-ao-tensorflow-e-suas-operacoes-basicas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    " \n",
    "#Primeiro definimos os números\n",
    " \n",
    "#criamos uma constante.\n",
    "x_1 = tf.constant(2.0,dtype=tf.float32)\n",
    " \n",
    "#A função tf.constant cria nossas constantes\n",
    "x_2 = tf.constant(5.0,dtype=tf.float32)\n",
    " \n",
    "#Aqui multiplicamos os dois resultados.\n",
    "mult = x_1*x_2\n",
    " \n",
    "#Aqui somamos as duas constante\n",
    "soma = x_1+x_2\n",
    " \n",
    "# Toda vez que quisermos executar usamos o método run\n",
    "# Isso nos permite compilar e executar o código solicitado.\n",
    "sess = tf.Session()\n",
    " \n",
    "#Aqui executamos a multiplicação\n",
    "print(sess.run(mult))\n",
    " \n",
    "#Aqui executamos a soma.\n",
    "print(sess.run(soma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações com vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.0\n",
      "[ 7.  5. 13.]\n"
     ]
    }
   ],
   "source": [
    "#criamos uma variável constante.\n",
    "vetor_1 = tf.constant([2.0,3.0,7.0],dtype=tf.float32)\n",
    " \n",
    "#A função tf.constant cria nossas constantes\n",
    "vetor_2 = tf.constant([5.0,2.0,6.0],dtype=tf.float32)\n",
    " \n",
    "#Aqui multiplicamos os dois vetores\n",
    "#Utilizei as funções multply e reduce_sum.\n",
    "#multply: multplica duas array elemento por elemento.\n",
    "#reduce_sum: faz o somatório dos elementos de um vetor\n",
    "mult = tf.reduce_sum(tf.multiply(vetor_1,vetor_2))\n",
    " \n",
    "#Aqui somamos os dois vetores de forma tradicional\n",
    "soma = vetor_1+vetor_2\n",
    " \n",
    "# Toda vez que quisermos execultar o métono run\n",
    "# Isso nos permite compilar e execultar o codigo solicitado.\n",
    "sess = tf.Session()\n",
    " \n",
    "#Aqui execultamos a multiplicação\n",
    "print(sess.run(mult))\n",
    " \n",
    "#Aqui execultamos a soma.\n",
    "print(sess.run(soma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  função tf.add\n",
    "\n",
    "Nesse exemplo duas variáveis $x_{1}$ e  $x_{2}$ entram como input e são somadas e logo depois gerado o output.\n",
    " ![Alt text](https://juliocprocha.files.wordpress.com/2017/08/imagem_6.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#tf.placeholder funciona como um input.\n",
    "#isso quer dizer que essas variáveis virão de fora\n",
    "x_1 = tf.placeholder(dtype=tf.float32)\n",
    " \n",
    "#Aqui os valores entrarão somente ná hora que\n",
    "# forem execultados.\n",
    "x_2 = tf.placeholder(dtype=tf.float32)\n",
    " \n",
    "output = tf.add(x_1,x_2)\n",
    " \n",
    "# Toda vez que quisermos execultar o métono run\n",
    "# Isso nos permite compilar e execultar o codigo solicitado.\n",
    "sess = tf.Session()\n",
    " \n",
    "#Aqui execultamos a soma.\n",
    "#Repare que passamos os valores para os placeholders na forma\n",
    "# de um dict. Eu acho isso interessante pois facilita a comunicação\n",
    "# com a API.\n",
    "print(sess.run(output,{x_1:1,x_2:2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Nesse caso temos uma estrutura semelhante ha de uma rede neural artificial, claro falta algumas coisas, mas como o foco é o processamento da informação isso não é um problema.\n",
    "\n",
    "Numerei os Nodes de 1 a 3 os inputs entram e são somados em cada Node e depois o resultado de cada um é multiplicado por uma constante e o output sai no utimo Node.\n",
    "\n",
    "![Alt text](https://juliocprocha.files.wordpress.com/2017/08/imagem_71.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.0\n"
     ]
    }
   ],
   "source": [
    "#Vamos declarar os inputs\n",
    "x_1 = tf.placeholder(dtype=tf.float32)\n",
    " \n",
    "x_2 = tf.placeholder(dtype=tf.float32)\n",
    " \n",
    "#Crio o primeiro Node\n",
    "#Ele soma os dois inputs\n",
    "Node_1 = tf.add(x_1,x_2)\n",
    " \n",
    "#Crio o segundo Node\n",
    "Node_2 = tf.add(x_1,x_2)\n",
    " \n",
    "#No terceiro Node esses valores entram Multplicados\n",
    "#Pelos seus respectivos pesos\n",
    "Node_3 = tf.add(Node_1*2,Node_2*5)\n",
    " \n",
    "# Toda vez que quisermos execultar o métono run\n",
    "# Isso nos permite compilar e execultar o codigo solicitado.\n",
    "sess = tf.Session()\n",
    " \n",
    "#Aqui execultamos a soma.\n",
    "#Repare que passamos os valores para os placeholders na forma\n",
    "# de um dict.\n",
    "print(sess.run(Node_3,{x_1:8,x_2:9}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fim 1\n",
    "\n",
    "\n",
    "### Inicio 2\n",
    "\n",
    "https://juliocprocha.wordpress.com/2017/11/21/multilayer-perceptron-com-tensorflow/\n",
    "\n",
    "![Alt text](https://juliocprocha.files.wordpress.com/2017/11/imagem_1.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "#Usaremos o pandas para algumas transformações basicas\n",
    "import pandas as pd\n",
    " \n",
    "#Numpy apenas para deixar as coisas mais rapidas\n",
    "import numpy as np\n",
    " \n",
    "#Irei utilizar essa função do sklearn para dividir o conjunto de treino e teste\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from bokeh.sampledata.iris import flowers as dados\n",
    "\n",
    "data=dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Definimos essa função para normalizar o coluna Species\n",
    "#Exemplo [preto,branco,preto,azul] => [0,1,0,2]\n",
    "def normalizeIris(x):\n",
    "    if x == \"virginica\":\n",
    "        return 0\n",
    "    elif x == \"versicolor\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    " \n",
    "#fazemos a função para transforma as labels em one-hot vectors\n",
    "#Exemplo [1,2,1,0] => [[0,1,0],[0,0,1],[0,1,0],[1,0,0]]\n",
    "def makeHotvector(y_data):\n",
    "    labels = []\n",
    "    for x in range(len(y_data)):\n",
    "        labels.append([0,0,0])\n",
    "        labels[x][y_data[x]] = 1\n",
    "    y_data = np.array(labels,dtype=np.float64)\n",
    "    return y_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Usamos o método .apply do Pandas para aplicar a função normaLizeIris\n",
    "#Na coluna \"Species\" lembre o que essa função faz\n",
    "data[\"species\"] = data[\"species\"].apply(normalizeIris)\n",
    " \n",
    "#Aqui separamos as features em uma variavel e as labels em outra\n",
    "x_data = data.drop(\"species\",axis=1).values\n",
    "y_data = data[\"species\"].values\n",
    " \n",
    "#Aqui separamos um pouco do dataset para treino e a outra parte para teste\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos começar a arquitetar a rede. Nossa rede possui dois hidden layers, o primeiro com 5 Nodes e o segundo com 3 Nodes, 4 inputs e 3 outputs como mostrado no esquema abaixo.\n",
    "\n",
    "![Alt text](https://juliocprocha.files.wordpress.com/2017/11/imagem_2.png)\n",
    "\n",
    "Essa não é a rede mais apropriada para esse tipo de problema, pois estamos lidando com uma tarefa de classificação de múltiplas classes, porem já que se trata de um dataset simples é perfeitamente possível treinarmos usando apenas a função logística sigmoide.\n",
    "\n",
    "Obs: Na prática é muito comum colocar uma função softmax na saída da rede.\n",
    "\n",
    "Se você reparou, acima transformamos os dados em one-hot-vectors, isso significa que cada output tem que ser um vetor do tipo [1,0,0],[0,1,0],[0,0,1] representando respectivamente a espécies 0, 1 e 2.\n",
    "\n",
    "Essa estratégia de treino é chamada one-vs-rest assim podemos treinar a rede para fazer aproximações de um output específico.\n",
    "\n",
    "Isso dito vamos começar a montar nossa rede, o primeiro passo é definir alguns parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quantidade inputs na rede\n",
    "n_input = 4\n",
    "#A proporção em que a rede irá atualizar cada peso\n",
    "#Chamamos também de alpha\n",
    "learning_rate = 0.01\n",
    "# A quantidade de unidades no primeiro layer\n",
    "n_hidden_unites_1 = 5\n",
    "#A quantidade de unidades no segundo layer\n",
    "n_hidden_unites_2 = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos criar o grapho da rede\n",
    "#Primeiro definimos a sessão\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui são os inputs da rede\n",
    "#Apenas os inputs do dataset são considerados.\n",
    "X = tf.placeholder(shape=[None,n_input],dtype=tf.float64)\n",
    " \n",
    "#Aqui ficam as Labels para treino\n",
    "#Essa parte do grafo não aparece no esquema.\n",
    "#mas aqui fica as labels que serão usadas como exemplo para a rede.\n",
    "y_ =  tf.placeholder(dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://juliocprocha.files.wordpress.com/2017/11/imagem_3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora iremos definir os pesos da rede\n",
    "#Esse é nosso primeira camada de pesos.\n",
    "W = {\"h1\":tf.Variable(tf.random_normal([n_input,n_hidden_unites_1],dtype=tf.float64),dtype=tf.float64),\n",
    "     \"h2\":tf.Variable(tf.random_normal([n_hidden_unites_1,n_hidden_unites_2],dtype=tf.float64),dtype=tf.float64)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os pesos nada mais são do que matrizes com o número de linhas igual ao número de inputs e o número de coluna igual a quantidade de unidades no primeiro hidden-layer.\n",
    "\n",
    "![](https://juliocprocha.files.wordpress.com/2017/11/imagem_41.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esse é o bias da rede\n",
    "b = {\"b1\":tf.Variable(tf.random_normal([n_hidden_unites_1],dtype=tf.float64),dtype=tf.float64),\n",
    "     \"b2\":tf.Variable(tf.random_normal([n_hidden_unites_2],dtype=tf.float64),dtype=tf.float64)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://juliocprocha.files.wordpress.com/2017/11/imagem_5.png)\n",
    "\n",
    "\n",
    "Agora definimos as funções de ativação de cada camada. como se trata de um problema simples usaremos somente a sigmoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoide aplicado a rede\n",
    "#O output do hidden_1\n",
    "out_hidden_1 = tf.nn.sigmoid(tf.matmul(X,W[\"h1\"])+b[\"b1\"])\n",
    "#o output do hidden_2 que alias será o usado como nosso output.\n",
    "out_hidden_2 = tf.nn.sigmoid(tf.matmul(out_hidden_1,W[\"h2\"])+b[\"b2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver a representação no esquema.\n",
    "\n",
    "![](https://juliocprocha.files.wordpress.com/2017/11/imagem_6.png)\n",
    "\n",
    "Isso definido vamos cuidar do treino dessa rede.\n",
    "\n",
    "No caso o que temos abaixo é uma média do erro do output da rede em relação a label usada como exemplo, usamos isso para orientar a atualização dos pesos na rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos o erro quadratico do out_hidden_2 em relação y_\n",
    "#isso permite deriva-lo e depois ajustar os pesos\n",
    "mse = tf.losses.mean_squared_error(y_,out_hidden_2)\n",
    " \n",
    "#Aqui eu uso o método gradientDescent para otimizar o parametro mse\n",
    "#Ele ira derivar o erro em relação a cada pesso da rede e fazer um atualização\n",
    "#para cima ou para abaixo proporcional ao learning_hate da rede\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui iremos inicializar todas as variaveis que compõe o grafo.\n",
    "\n",
    "#Uma maneira de carregar as variaveis para a memoria.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso permite ao TensorFlow inicializar todas as operações que compoe o grafo gerando assim o output.\n",
    "\n",
    "Agora vem uma das partes mais importantes que é a forma que a rede ira ser treinada. Eu escolhi um loop dentro de um loop onde o algoritmo treina de forma incremental exemplo por exemplo (online learning.) porem de maneira aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#Realizar 1000 interações no dataset\n",
    "for x in range(100):\n",
    "    print(x)#para ver o andamento do treino\n",
    " \n",
    "    #Iremos dar loop do tamanho do dataset\n",
    "    for _ in range(len(x_train)):\n",
    "        #Aqui seleciono uma instancia aliatória do dataset\n",
    "        i = np.random.randint(len(x_train))\n",
    "        x = np.array([x_train[i]])\n",
    "        y = np.array([y_train[i]])\n",
    " \n",
    "        #Aqui treinamos a rede uma iteração de cada vez\n",
    "        train_step.run(feed_dict={X:x,y_:y},session=sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe a forma que a rede é treinada. Ela minimiza o erro exemplo por exemplo isso é conhecido camo Stochastic gradient descent.\n",
    "\n",
    "Depois de treinar a rede podemos ver alguns indices básicos de acuracia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 22  4]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Aqui iremos medir a precisão do modelo\n",
    "#colocamos a rede para validar os outputs no conjunto de teste\n",
    "outputs = out_hidden_2.eval(feed_dict={X:x_test},session=sess)\n",
    " \n",
    "#Aqui convertemos de one-hot-vector para discreto\n",
    "labels = [x.argmax() for x in y_test]\n",
    "predictions = [x.argmax() for x in outputs]\n",
    " \n",
    "#aplicamos confusion matrix para ver o desepenho\n",
    "cm = confusion_matrix(labels,predictions)\n",
    " \n",
    "#aqui vemos a acuracia do algoritmo.\n",
    "acuracy = accuracy_score(labels,predictions)\n",
    " \n",
    "print(cm)\n",
    "print(acuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
